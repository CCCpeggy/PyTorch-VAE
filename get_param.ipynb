{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "from models import ScreenVAE\n",
    "from experiment import VAEXperiment\n",
    "\n",
    "import sys\n",
    "sys.path.append('../procedural-advml')\n",
    "from utils_noise import PlotGaborAni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"configs/my_vae.yaml\"\n",
    "encode_path = os.path.join(r\"logs\\Screentone-VAE\\version_54\", r\"checkpoints\\epoch=47-step=258863.ckpt\")\n",
    "decode_path = os.path.join(r\"logs\\ParamDecoder\", r\"epoch-32.ckpt\")\n",
    "global_path = r\"D:\\shared\\datasets\\20220214\\gabor_noise_band_5_10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in -> in 8 層，in -> out 8 層\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(MLP, self).__init__()\n",
    "        modules = []\n",
    "        for _ in range(8):\n",
    "            modules.append(\n",
    "                nn.Sequential(nn.Linear(in_channel, in_channel))\n",
    "            )\n",
    "        modules.append(\n",
    "            nn.Sequential(nn.Linear(in_channel, out_channel))\n",
    "        )\n",
    "        self.fc = nn.Sequential(*modules)\n",
    "        self.loss_mse = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def loss(self, real, fake):\n",
    "        return self.loss_mse(real, fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param(x):\n",
    "    p = {}\n",
    "    p['num_kern'] = int(x[0] * 200)\n",
    "    p['ksize'] = int(x[1] * 40)\n",
    "    p['sigma'] = float(x[2] * 20)\n",
    "    p['theta'] = float(x[3] * 3.14)\n",
    "    p['lambd'] = float(x[4] * 10)\n",
    "    p['sides'] = int(x[5] * 12)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 解析路徑中的參數至 tensor\n",
    "def parse_path(path):\n",
    "    X = np.zeros((len(path), 6))\n",
    "    axis0_idx = 0\n",
    "    for p in path:\n",
    "        p = os.path.basename(p)[:-4]\n",
    "        x = [float(s) for s in p.split(\"_\")]\n",
    "        x[0] /= 200\n",
    "        x[1] /= 40\n",
    "        x[2] /= 20\n",
    "        x[3] /= 3.14\n",
    "        x[4] /= 10\n",
    "        x[5] /= 12\n",
    "        X[axis0_idx] = np.array(x)\n",
    "        axis0_idx += 1\n",
    "    return torch.FloatTensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file, 'r', encoding=\"utf-8\") as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(\"error\", exc)\n",
    "output_path = f\"./{config['logging_params']['save_dir']}ParamDecoder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading encoder\n",
      "Loading encoder ... Done\n"
     ]
    }
   ],
   "source": [
    "encoder = ScreenVAE(**config['model_params'])\n",
    "print(\"Loading encoder\")\n",
    "encoder.load_state_dict(torch.load(encode_path))\n",
    "print(\"Loading encoder ... Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備圖片\n",
    "# print(\"Preparing Dataset\")\n",
    "# experiment = VAEXperiment(encoder, config['exp_params'], select_rect=True)\n",
    "# dataloader = experiment.predict_dataloader()\n",
    "# print(\"Preparing Dataset ... Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading decoder\n",
      "Loading decoder ... Done\n"
     ]
    }
   ],
   "source": [
    "# create decoder\n",
    "decoder = MLP(config['model_params'][\"latent_dim\"], 6)\n",
    "print(\"Loading decoder\")\n",
    "decoder.load_state_dict(torch.load(decode_path))\n",
    "print(\"Loading decoder ... Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 產生一張隨機圖片\n",
    "def getRandomImg(size):\n",
    "    s_num_kern = random.randint(5, 200)\n",
    "    s_ksize = random.randint(3, 40)\n",
    "    s_sigma = random.uniform(2, 20)\n",
    "    s_theta = random.uniform(0, np.pi)\n",
    "    s_lambd = random.uniform(5, 10)\n",
    "    s_sides = random.randint(1, 12)\n",
    "    img = PlotGaborAni(s_num_kern, s_ksize, s_sigma, s_theta, s_lambd, s_sides, size=size)\n",
    "    x = [s_num_kern / 200, s_ksize / 40, s_sigma / 20, s_theta / 3.14, s_lambd / 10, s_sides / 12]\n",
    "    return img, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 產生 n 張隨機圖片\n",
    "def getRandomImgs(n, size):\n",
    "    image = []\n",
    "    X = []\n",
    "    for i in range(n):\n",
    "        img, x = getRandomImg(size)\n",
    "        X.append(x)\n",
    "        image.append(img)\n",
    "    return image, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成結果圖\n",
    "# def output(real, fake):\n",
    "#     size = len(real)\n",
    "#     img_size = 128\n",
    "#     margin = 5\n",
    "#     next_distance = img_size + margin\n",
    "#     imgs = np.zeros((size * next_distance - margin, 2 * img_size + margin), int)\n",
    "#     for i in range(size):\n",
    "#         try:\n",
    "#             real_img = PlotGaborAni(**param(real[i, :]))\n",
    "#             fake_img = PlotGaborAni(**param(fake[i, :]))\n",
    "#             startH = i * next_distance\n",
    "#             imgs[startH:startH + img_size, :img_size] = real_img\n",
    "#             imgs[startH:startH + img_size, next_distance:] = fake_img\n",
    "#         except:\n",
    "#             print(f\"error {fake[i, :]}, {real[i, :]}\")\n",
    "#     cv2.imwrite(f\"{output_path}/re-generate.png\", imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成結果圖 (list)\n",
    "def output_list(X):\n",
    "    w_size, h_size = len(X), len(X[0])\n",
    "    img_size = 512\n",
    "    margin = 5\n",
    "    next_distance = img_size + margin\n",
    "    imgs = np.zeros((h_size * next_distance - margin, w_size * next_distance - margin), int)\n",
    "    for i in range(w_size):\n",
    "        x = X[i]\n",
    "        for j in range(h_size):\n",
    "            try:\n",
    "                startH = j * next_distance\n",
    "                startW = i * next_distance\n",
    "                imgs[startH:startH + img_size, startW:startW + img_size] = PlotGaborAni(size=img_size, **param(x[j, :]))\n",
    "            except:\n",
    "                print(f\"error {x[j, :]}\")\n",
    "    cv2.imwrite(f\"{output_path}/re-generate.png\", imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 自動生成並辨識參數重建\n",
    "# # get real parameter\n",
    "# imgs, real = getRandomImgs(5)\n",
    "# # get fake parameter\n",
    "# mu, log_var = encoder.encode(imgs.float())\n",
    "# z = encoder.reparameterize(mu, log_var)\n",
    "# fake = decoder(z)\n",
    "\n",
    "# loss = decoder.loss(real, fake)\n",
    "# fake = fake.cpu().detach().numpy()\n",
    "# real = real.cpu().detach().numpy()\n",
    "\n",
    "# output_list([real, fake])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# 自動生成並辨識參數重建多次\n",
    "# get real parameter\n",
    "real_img_size = 1024\n",
    "imgs, real = getRandomImgs(5, real_img_size)\n",
    "# get fake parameter\n",
    "\n",
    "real = torch.FloatTensor(real)\n",
    "X = [real.cpu().detach().numpy()]\n",
    "img_size = config['exp_params']['img_size']\n",
    "for _ in range(10):\n",
    "    print(_)\n",
    "    def RandomCrop(ori_size, crop_size):\n",
    "        def crop(img):\n",
    "            h, w = random.randrange(0, ori_size - crop_size), random.randrange(0, ori_size - crop_size)\n",
    "            return img[h:h+crop_size, w:w+crop_size]\n",
    "        return crop\n",
    "    tmp_imgs = [transforms.ToTensor()(RandomCrop(real_img_size, img_size)(img)) for img in imgs]\n",
    "    tmp_imgs = torch.stack(tmp_imgs, 0)\n",
    "    \n",
    "    mu, log_var = encoder.encode(tmp_imgs.float())\n",
    "    z = encoder.reparameterize(mu, log_var)\n",
    "    fake = decoder(z)\n",
    "\n",
    "    loss = decoder.loss(real, fake)\n",
    "    X.append(fake.cpu().detach().numpy())\n",
    "\n",
    "# output_list([X[0], X[1], X[-1]])\n",
    "output_list(X)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6d33e134d541535d1949bd790bf258ae0d8667d067eb6376f94ba9873c44cce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('Pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
